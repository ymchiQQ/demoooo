# seq2seq elvc demo page

## Welcome to Demo Pages

[Demo pages](https://ymchiqq.github.io/seq2seq-elvc/)

## Abstact

The electrolaryngeal speech (EL speech) is typically spoken with an electrolarynx device that generates excitation signals to substitute human vocal fold vibrations. Because the excitation signals cannot perfectly characterize sound sources generated by vocal folds, the naturalness and intelligibility of the EL speech are inevitably worse than that of the natural speech (NL speech). To improve speech naturalness, statistical models, such as Gaussian mixture models and deep-learning-based models, have been employed for EL speech voice conversion (ELVC). The ELVC task aims to convert EL speech into NL speech through an ELVC model. To implement a frame-wise ELVC system, accurate feature alignment is crucial for model training. However, the abnormal acoustic characteristics of the EL speech cause misalignments and accordingly limit the ELVC performance. To address this issue, we propose a novel ELVC system based on sequence-to-sequence (seq2seq) modeling with text-to-speech (TTS) pretraining.  The seq2seq model involves an attention mechanism to concurrently perform representation learning and alignment. Meanwhile, TTS pretraining provides efficient training with limited data. Experimental results show that the proposed ELVC system yields notable improvements in terms of standardized evaluation metrics and subjective listening tests over a well-known frame-wise ELVC system.

## Model

* MT-CLDNN: multi-task CLDNN[^first]
* TFS: train from sractch with seq2seq model
* PT: seq2seq model with TTS pretraining

## Audio samples

### sample EL01-NL01

|   Model   | transcription: 他捐了很多衣物給災區 (ta juan le hen duo yi wu gei zai qu) |
|:---------:|:-------------------------------------------------------------------:|
| EL speech | <audio src="audio/el01/EL01_281.wav" controls preload></audio> |
| MT-CLDNN  | <audio src="audio/el01_nl01/mtcldnn/EL01-NL01_MTCLDNN_h5_GV_no0th_281.wav" controls preload></audio> |
|    TFS    | <audio src="audio/el01_nl01/tfs/EL01-NL01_TFS_281.wav" controls preload></audio> |
|    PT     | <audio src="audio/el01_nl01/pt/EL01-NL01_PT_281.wav" controls preload></audio> |
| NL speech | <audio src="audio/nl01/NL01_281.wav" controls preload></audio> |


|   Model   |transcription: 我把不用的家具送人了 (wo ba bu yong de jia ju song ren le)|
|:---------:|:-------------------------------------------------------------------:|
| EL speech | <audio src="audio/el01/EL01_284.wav" controls preload></audio> |
| MT-CLDNN  | <audio src="audio/el01_nl01/mtcldnn/EL01-NL01_MTCLDNN_h5_GV_no0th_284.wav" controls preload></audio> |
|    TFS    | <audio src="audio/el01_nl01/tfs/EL01-NL01_TFS_284.wav" controls preload></audio> |
|    PT     | <audio src="audio/el01_nl01/pt/EL01-NL01_PT_284.wav" controls preload></audio> |
| NL speech | <audio src="audio/nl01/NL01_284.wav" controls preload></audio> |

|   Model   | transcription: 那個牆上掛著一幅油畫 (na ge qiang shang gua zhu yi fu you hua)|
|:---------:|:-------------------------------------------------------------------:|
| EL speech | <audio src="audio/el01/EL01_287.wav" controls preload></audio> |
| MT-CLDNN  | <audio src="audio/el01_nl01/mtcldnn/EL01-NL01_MTCLDNN_h5_GV_no0th_287.wav" controls preload></audio> |
|    TFS    | <audio src="audio/el01_nl01/tfs/EL01-NL01_TFS_287.wav" controls preload></audio> |
|    PT     | <audio src="audio/el01_nl01/pt/EL01-NL01_PT_287.wav" controls preload></audio> |
| NL speech | <audio src="audio/nl01/NL01_287.wav" controls preload></audio> |


### sample EL01-NL02

## Reference

[^first]: K.  Kobayashi  and  T.  Toda,  “Implementation of low-latency electrolaryngeal speech enhancement based onmulti-task  cldnn,”  inProceedings of 2020 28th EU-SIPCO, 2021, pp. 396–400.

